#!/usr/bin/env python

import numpy as np
from quasarnet import io
import fitsio
import sys

import argparse

parser=argparse.ArgumentParser()

parser.add_argument('--data',type=str, required=True,
        help='input data file')

parser.add_argument('--nsplits',type=int, required=True,
        help='number of splits')

parser.add_argument('--training-proportion',type=float, required=False, default=None,
        help='for each split, proportion to use for training')

parser.add_argument('--training-number',type=float, required=False, default=None,
        help='for each split, proportion to use for training')

parser.add_argument('--independent-test-sets', required=False, action='store_true', default=False,
        help='ensure that test sets are independent')

parser.add_argument('--independent-training-sets', required=False, action='store_true', default=False,
        help='ensure that training sets are independent')

parser.add_argument('--seed',type=int, required=False, default=0,
        help='number of splits')

parser.add_argument('--out-prefix',type=str, required=True,
        help='output file prefix')

args=parser.parse_args()

## Get the number of spectra in the data file.
h = fitsio.FITS(args.data)
nspec = h[0].get_dims()[0]

if (args.training_proportion is None) and (args.training_number is None):
    raise ValueError('No training size given!')
elif (args.training_proportion is not None) and (args.training_number is not None):
    raise ValueError('Both training size options given!')
elif (args.training_number is not None):
    args.training_proportion = args.training_number/nspec

## Raise errors if the training proportion is too high for independent training
## sets, or too low for indepenedent test sets to be made.
if args.independent_test_sets and (args.training_proportion<0.5):
    raise ValueError('Cannot have independent test sets with training proportion {}.'.format(args.training_proportion))
if args.independent_training_sets and (args.training_proportion>0.5):
    raise ValueError('Cannot have independent training sets with training proportion {}.'.format(args.training_proportion))



## Determine the number of random orderings we will need in order to generate
## enough training data sets of the desired size.
if (not args.independent_test_sets) and (not args.independent_training_sets):
    # Make random splits straightforwardly.
    print('INFO: Making {} random splits of the data.'.format(args.nsplits))
    nsplits_round = 1
    nrounds = args.nsplits.astpe(int)

elif args.independent_test_sets:
    # Make splits such that test sets are independent (where possible).
    nsplits_round = np.floor(1/(1-args.training_proportion)).astpe(int)
    nrounds = np.ceil(args.nsplits/nsplits_round).astpe(int)
    print('INFO: Making {} splits of the data, containing {} subsets of {} splits each, each of which will allow for independent test sets.'.format(args.nsplits,nrounds,nsplits_round))

    # Print if the independent test sets do not cover the whole dataset.
    if args.training_proportion*nsplits_round != 1.0:
        print('WARN: training proportion of {} does not allow for independent test datasets to cover the whole dataset.'.format(args.training_proportion))

elif args.independent_training_sets:
    # Make splits such that training sets are independent (where possible).
    nsplits_round = np.floor(1/(args.training_proportion)).astpe(int)
    nrounds = np.ceil(args.nsplits/nsplits_round).astpe(int)
    print('INFO: Making {} splits of the data, containing {} subsets of {} splits each, each of which will be independent training sets.'.format(args.nsplits,nrounds,nsplits_round))

    # Print if the independent test sets do not cover the whole dataset.
    if args.training_proportion*nsplits_round != 1.0:
        print('WARN: training proportion of {} does not allow for independent training datasets to cover the whole dataset.'.format(args.training_proportion))

## Make a random generator.
state = np.random.RandomState(seed=args.seed)

## For each round:
nsplits_made = 0
for round in range(nrounds):

    # Generate random weights for each spectrum.
    w = state.uniform(size=nspec)

    ## For each split in this round:
    for roundsplit in range(nsplits_round):

        if nsplits_made<args.nsplits:

            # Select the objects which we want to be in our training set.
            if (not args.independent_test_sets) and (not args.independent_training_sets):
                wtrain = w<args.training_proportion
            elif args.independent_test_sets:
                wtest = (w>=args.training_proportion*roundsplit) * (w<args.training_proportion*(roundsplit+1))
                wtrain = (~wtest)
            elif args.independent_training_sets:
                wtrain = (w>=args.training_proportion*roundsplit) * (w<args.training_proportion*(roundsplit+1))

            print(round,roundsplit,wtrain.sum()/len(wtrain))

            """
            # Make a file and write the chosen training data to it.
            h_split = fitsio.FITS(args.out_prefix+'_{}_{}.fits'.format(round,roundsplit),'rw',clobber=True)
            h_split.write(h[0][:,:][w_split,:])
            h_split.write(h[1][:][w_split],header=h[1].read_header())
            h_split.close()
            """
            nsplits_made += 1
