{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QuasarNET: the Quality Assesment notebook\n",
    "\n",
    "This notebook will walk you through how to run [QuasarNET](https://arxiv.org/pdf/1808.09955.pdf]):\n",
    " * load training and validation data\n",
    " * train the network (on a small training sample, optional)\n",
    " * load pre-trained weights\n",
    " * plot example spectra\n",
    " * produce QA plots and confusion matrix\n",
    "\n",
    "#### Installation instructions (requires python3):\n",
    "##### - on a standard system\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/ngbusca/QuasarNET.git\n",
    "cd QuasarNET\n",
    "pip install -r requirements.txt --user\n",
    "python setup.py install --user\n",
    "```\n",
    "\n",
    "##### - at NERSC (e.g. if you run this notebook at jupyter.nersc.gov)\n",
    "\n",
    "```bash\n",
    "conda create -n qnet python=3 qnet scipy numpy fitsio h5py ipykernel\n",
    "source activate qnet\n",
    "pip install tensorflow\n",
    "pip install keras>=2.2.4\n",
    "git clone https://github.com/ngbusca/QuasarNET.git\n",
    "cd QuasarNET\n",
    "python setup.py install\n",
    "```\n",
    "\n",
    "#### - downloading the data \n",
    "These data are a reprocessing of data release 12 (DR12) of the Sloan Digital Sky Survey (https://www.sdss.org/dr12/)\n",
    "\n",
    "The data are available on Kaggle: https://www.kaggle.com/ngbusca/qnet_data\n",
    "\n",
    "A practical way to download the data is to use the [kaggle-api](https://github.com/Kaggle/kaggle-api)\n",
    "\n",
    "Download the data to the `QuasarNET/data` directory.\n",
    "\n",
    "#### - download the pre-trained weights\n",
    "The pre-trained weights are available at: https://www.kaggle.com/ngbusca/qnet_trained_models\n",
    "\n",
    "Download the weights to the `QuasarNET/weights` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import fitsio\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from quasarnet.models import QuasarNET, custom_loss\n",
    "from quasarnet.io import read_truth, read_data, wave, objective\n",
    "from quasarnet.utils import process_preds, absorber_IGM\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the validation and training data\n",
    "\n",
    "The full data sample was divided into 8 80/20 training/validation splits and pre-trained weights are available for each split. The random split to load is controled by the `isplit` variable.\n",
    "\n",
    "The next cell loads first the truth table, the full data sample and the chosen training sample.\n",
    "It finally excludes the training data from the full sample to form the validation sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: reading data from ../data/data_dr12.fits\n",
      "INFO: removing 20766 spectra missing in truth\n",
      "INFO: found (617289,) spectra in file ../data/data_dr12.fits\n",
      "INFO: removing 2567 spectra with zero weights\n",
      "INFO: removing 7 spectra with zero flux\n"
     ]
    }
   ],
   "source": [
    "isplit=0\n",
    "truth_file=(['../data/truth_DR12Q.fits'])\n",
    "truth = read_truth(truth_file)\n",
    "tids_full,X_full,Y_full,z_full,bal_full = read_data(['../data/data_dr12.fits'], truth)\n",
    "\n",
    "data_file = '../data/reshuffles_new/tids/data_train_{}.fits'.format(isplit)\n",
    "h = fitsio.FITS(data_file)\n",
    "tids_train = h[1]['TARGETID'][:]\n",
    "w = np.in1d(tids_full, tids_train)\n",
    "X_train = X_full[w]\n",
    "Y_train = Y_full[w]\n",
    "z_train = z_full[w]\n",
    "bal_train = bal_full[w]\n",
    "\n",
    "## to get the validation data, first read everything, \n",
    "## then remove the spectra in the training sample\n",
    "w = ~np.in1d(tids_full, tids_train)\n",
    "tids_val = tids_full[w]\n",
    "X_val = X_full[w]\n",
    "Y_val = Y_full[w]\n",
    "z_val = z_full[w]\n",
    "bal_val = bal_full[w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the \"features\" that the network is trained to recognize\n",
    "\n",
    "The features are defined by their rest wavelength. \n",
    "A dictionary `{feature_name:feature_wavelength}` is defined in `quasarnet.util.absorber_IGM`, which currently contains typical quasar broad emission lines. It could be easily extended to include other features by extending the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=['LYA','CIV(1548)','CIII(1909)', 'MgII(2796)','Hbeta','Halpha']\n",
    "lines_bal=['CIV(1548)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the network (optional).\n",
    "\n",
    "The best way to train the network is to use a multicore computer. Training over 100 epochs on a full training sample takes ~24h on a standard 24 core unit, and ~7 hours on a Cori/NERSC node (64 cores).\n",
    "\n",
    "As an example, the following two cells will instantiate the model (first cell) and run the training (second cell) on a single epoch and fewer training spectra. You can run the second cell many times to train over many epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 10000\n",
    "nbins = X_train.shape[1]\n",
    "model = QuasarNET((nbins,1), nlines=len(lines)+len(lines_bal))\n",
    "optimizer = Adam()\n",
    "loss = [custom_loss]*(len(lines)+len(lines_bal))\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[])\n",
    "objective, sample_weight = objective(z_train[:ntrain],Y_train[:ntrain],bal_train[:ntrain],lines=lines,lines_bal=lines_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 5088/10000 [==============>...............] - ETA: 26s - loss: 4.1133 - conc_box_0_loss: 0.4920 - conc_box_1_loss: 0.5871 - conc_box_2_loss: 0.6513 - conc_box_3_loss: 0.7036 - conc_box_4_loss: 0.6274 - conc_box_5_loss: 0.3753 - conc_box_6_loss: 0.6767"
     ]
    }
   ],
   "source": [
    "loss_history = model.fit(X_train[:ntrain,:,None], objective, epochs=1, batch_size=32, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a pre-trained model\n",
    "\n",
    "The following cell loads pre-trained weights for the network, corresponding to the split defined earlier. The pre-training was done over the full training data sample and 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../weights/qn_train_{}.h5'.format(isplit),custom_objects={'custom_loss':custom_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example spectra\n",
    "\n",
    "Let's now take a look at the network output by examining a few examples. If you skipped loading the pre-trained weights you will be looking at the model you trained (it's actually not that bad!).\n",
    "\n",
    "The network outputs confidences and positions of the features defined earlier. The following plot shows a spectrum from the validation sample and the detected features. You can change the index `ival` to change the spectrum to be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ival = 10\n",
    "p=model.predict(X_val[ival:ival+1,:,None])\n",
    "c_line, z_line, zbest, c_line_bal, z_line_bal = process_preds(p, lines, lines_bal)\n",
    "plt.plot(wave, X_val[ival])\n",
    "plt.title('THIND_ID = {}, z$_{{ann}}$ = {}, z$_{{pred}}$ = {}'.format(tids_val[ival],z_val[ival],round(zbest[0],3)))\n",
    "m = X_val[ival].min()\n",
    "M = X_val[ival].max()\n",
    "plt.grid()\n",
    "plt.ylim(m-2,M+2)\n",
    "for il,l in enumerate(lines):\n",
    "    lam = absorber_IGM[l]*(1+z_line[il])\n",
    "    w = abs(wave-lam)<100\n",
    "    m = X_val[ival,w].min()-1\n",
    "    M = X_val[ival,w].max()+1\n",
    "    plt.plot([lam,lam], [m,M],'r--', alpha=0.1+0.9*c_line[il])\n",
    "    plt.text(lam,M+0.5,'c$_{{{}}}={}$'.format(l,round(c_line[il,0],3)),\n",
    "             horizontalalignment='center',alpha=0.1+0.9*c_line[il])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality Assesment\n",
    "##### Purity and completeness (all redshift confused)\n",
    "\n",
    "QuasarNET assumes a spectrum corresponds to a quasar if there are at least `ndetect` features detected with a confidence higher than a threshold confidence (`c_th`). The redshift is defined as that of the most confident line.\n",
    "\n",
    "The following cells calculate the predictions of the network on the validation sample and plot the purity and completeness as a function of threshold confidence and minimum number of detected lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict the validation sample\n",
    "print('calculating predictions')\n",
    "p_val = model.predict(X_val[:,:,None])\n",
    "print('done')\n",
    "c_line, z_line, zbest, c_line_bal, z_line_bal = process_preds(p_val, lines, lines_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_th=np.arange(0,1,0.01)\n",
    "pur = c_th*0\n",
    "com = c_th*0\n",
    "isqso_truth = (Y_val.argmax(axis=1)==2) | (Y_val.argmax(axis=1)==3)\n",
    "dv_max = 6000./300000.\n",
    "zgood = (z_val>0) & (abs(zbest-z_val) < dv_max*(1+z_val))\n",
    "ndetect = 2\n",
    "for i,cth in enumerate(c_th):\n",
    "    isqso_qn = (c_line>cth).sum(axis=0)>=ndetect\n",
    "    ntrue_positives = (isqso_qn & zgood).sum()\n",
    "    pur[i] = ntrue_positives/isqso_qn.sum()\n",
    "    com[i] = (isqso_qn & zgood & isqso_truth).sum()/isqso_truth.sum()\n",
    "    \n",
    "plt.plot(c_th, pur)\n",
    "plt.plot(c_th, com)\n",
    "plt.ylim(0.98,1.0)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality Assesment\n",
    "##### Purity and completenss vs. redshift\n",
    "\n",
    "The following plot show the purity and completeness vs. redshift. \n",
    "\n",
    "For a given redshift interval, defined using the network predictions, the purity is the fraction of spectra in the sample that have a predicted redshift better than 6000 km/s from the true redshift ( classification).\n",
    "\n",
    "For a given redshift interval, defined using the true redshift, the completeness is the fraction of quasar spectra in the sample that the network detects with a redshift better than 6000 km/s from the true redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_th = 0.7\n",
    "ndetect = 1\n",
    "isqso_qn = (c_line>c_th).sum(axis=0)>=ndetect\n",
    "\n",
    "dz_int = 0.5\n",
    "zmin = 0\n",
    "zmax = 7\n",
    "z_int = np.arange(zmin+dz_int/2,zmax+dz_int/2,dz_int)\n",
    "pur_z = z_int*0\n",
    "com_z = z_int*0\n",
    "for i, zint in enumerate(z_int):\n",
    "    w0 = isqso_qn & zgood & (abs(zbest-zint)<dz_int/2)\n",
    "    w1 = isqso_qn & (abs(zbest-zint)<dz_int/2)\n",
    "    pur_z[i] = w0.sum()/w1.sum()\n",
    "    \n",
    "    w0 = isqso_qn & isqso_truth & zgood & (abs(z_val-zint)<dz_int/2)\n",
    "    w1 = isqso_truth & (abs(z_val-zint)<dz_int/2)\n",
    "    com_z[i] = w0.sum()/w1.sum()\n",
    "    \n",
    "plt.step(z_int-dz_int/2, pur_z, where='post')\n",
    "plt.step(z_int-dz_int/2, com_z, where='post')\n",
    "plt.grid()\n",
    "plt.ylim(0.96,1.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality assesment\n",
    "##### Confusion matrix\n",
    "\n",
    "The following cell computes the confusion matrix, i.e. the fraction of spectra in the true class i that are classified in class j by the network.\n",
    "\n",
    "Note that while the true classes are `STAR`, `GALAXY`, `QSO LOZ`, `QSO HIZ`, the network classifies into `NOT QSO`, `QSO LOZ`, `QSO HIZ`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nspec, nclass = Y_val.shape\n",
    "classes = ['STAR','GAL','Q_LZ','Q_HZ','BAD']\n",
    "classes_qn = ['NOT_Q','Q_LZ','Q_HZ']\n",
    "nclass_qn = 3\n",
    "conf_mat=np.zeros((nclass, nclass_qn))\n",
    "class_qn = np.zeros((3,nspec), dtype=bool)\n",
    "class_qn[0] = ~isqso_qn\n",
    "class_qn[1] = isqso_qn & (zbest<2.1)\n",
    "class_qn[2] = isqso_qn & (zbest>=2.1)\n",
    "print('{:^6} | '.format(\"\"),end=\"\")\n",
    "print('{:^6} | '.format('NSPEC'),end=\"\")\n",
    "for c in classes_qn:\n",
    "    print('{:^6} | '.format(c),end=\"\")\n",
    "print(\"\")\n",
    "for i in range(nclass):\n",
    "    w = Y_val.argmax(axis=1)==i\n",
    "    print('{:^6} | '.format(classes[i]),end=\"\")\n",
    "    print('{:^6} | '.format(w.sum()),end=\"\")\n",
    "    for j in range(nclass_qn):\n",
    "        conf_mat[i,j] = (w & class_qn[j]).sum()/w.sum()\n",
    "        print(\"{:^6} | \".format(round(conf_mat[i,j]*100,2)), end=\"\")\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnet",
   "language": "python",
   "name": "qnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
